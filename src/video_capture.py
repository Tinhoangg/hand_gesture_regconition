import cv2
import time
import os

# Má»Ÿ camera laptop
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera.")
    exit()

# Láº¥y kÃ­ch thÆ°á»›c khung hÃ¬nh
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

fourcc = cv2.VideoWriter_fourcc(*'mp4v')
fps = 30.0
num_videos = 16  # sá»‘ láº§n quay
duration = 3  # thá»i gian má»—i video (giÃ¢y)

for i in range(1, num_videos + 1):
    filename = f"026_001_00{i}.mp4"
    out = cv2.VideoWriter(filename, fourcc, fps, (frame_width, frame_height))

    print(f"\nğŸ¬ Chuáº©n bá»‹ quay video {i}/{num_videos}...")
    time.sleep(1)  # nghá»‰ 1s Ä‘á»ƒ báº¡n chuáº©n bá»‹

    start_time = time.time()
    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c khung hÃ¬nh.")
            break

        elapsed = time.time() - start_time
        remaining = duration - elapsed

        # Hiá»ƒn thá»‹ Ä‘áº¿m ngÆ°á»£c trÃªn video
        if remaining > 0:
            cv2.putText(frame, f"Recording {i}/{num_videos} - {remaining:.1f}s",
                        (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        out.write(frame)
        cv2.imshow('Recording Gesture Dataset', frame)

        # Dá»«ng sau 3s
        if elapsed >= duration:
            break

        if cv2.waitKey(1) & 0xFF == ord('q'):
            cap.release()
            out.release()
            cv2.destroyAllWindows()
            exit()

    out.release()
    print(f"âœ… Video {i} Ä‘Ã£ lÆ°u: {filename}")

    # Nghá»‰ 1 giÃ¢y giá»¯a cÃ¡c láº§n quay
    time.sleep(1)

cap.release()
cv2.destroyAllWindows()
print("\nğŸ HoÃ n táº¥t quay 16 video gesture!")

# import cv2
# import numpy as np
# import os

# # === 1. ÄÆ°á»ng dáº«n video gá»‘c ===
# video_path = "D:/Semester/Semester5/DPL302/Project/dataset/Milk/021_001_003.mp4"   # Ä‘á»•i theo file cá»§a báº¡n
# output_video = "hand_gesture_30frames.mp4"  # video sau khi giáº£m frame
# num_samples = 60                  # sá»‘ frame muá»‘n chá»n Ä‘á»u

# # === 2. Äá»c video gá»‘c ===
# cap = cv2.VideoCapture(video_path)
# frames = []

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         break
#     frames.append(frame)

# cap.release()

# total_frames = len(frames)
# print(f"ğŸ“¹ Video cÃ³ tá»•ng {total_frames} frame.")

# # === 3. Chá»n 30 frame Ä‘á»u nhau ===
# if total_frames == 0:
#     raise ValueError("KhÃ´ng Ä‘á»c Ä‘Æ°á»£c video hoáº·c video rá»—ng!")

# idx = np.linspace(0, total_frames - 1, num_samples).astype(int)
# sampled_frames = [frames[i] for i in idx]

# # === 4. LÆ°u láº¡i thÃ nh video má»›i ===
# frame_height, frame_width = sampled_frames[0].shape[:2]
# fourcc = cv2.VideoWriter_fourcc(*'mp4v')
# fps = 30.0  # báº¡n cÃ³ thá»ƒ Ä‘á»ƒ 30 hoáº·c 15 tuá»³ Ã½

# out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))

# for frame in sampled_frames:
#     out.write(frame)

# out.release()

# print(f"âœ… Video má»›i Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {output_video}")




